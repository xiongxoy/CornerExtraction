%Template for ICIP-2014 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage[ruled, linesnumbered]{algorithm2e}


% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Vertex Extraction for Convex and Concave Polygons}
% TODO 进行拼写检查
%
% Single address.
% ---------------
\name{Zhou Xiong}
\address{Harbin Institute of Technology\\Computer Science and Engneering\\Harbin, China}

%
% For example:
% ------------
%\address{School\\
%       Department\\
%       Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%       {School A-B\\
%       Department A-B\\
%       Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%       while at ...}}
%       {School C-D\\
%       Department C-D\\
%       Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}

Locating the vertices of a polygonal digital contour is an important but seldomly addressed problem.
We propose two fast and robust methods for vertex detection in convex and non-convex polygons.
The first method is dedecated to convex polygons. We first map each point to the unit circle, then apply
k-means to assign points the corresponding lines, vertices are computed as the intersection of adjacent lines.
The mapping in the method can preserve the topological order of points, which is a key contribution of our method.
The second method does not require the polygon to be convex. We use the RANSAC approach to fit the polygon. A polygon
is modelded as consecutive lines, we iterate several times and choose the model with highest inliner rate. Expriemnts
on natural and synthetical images are given to show the validity of our approach.

\end{abstract}
%
\begin{keywords}
  Vertex detection, Convex Hull, K-means, RANSAC
\end{keywords}
%
\section{Introduction}
\label{sec:intro}
The work on the detection of dominant points started from the research of Attneave who proposed that the local maximum
curvature points on a curve have a rich information content and are sufficient to characterize this curve have a rich
rich infomation content and are sufficient to characterize this curve. A method for detection of
dominant points can lead to a good representation of a planar shape at different resolutions.

In addition, a representation of a planar shape based on dominant points has some advantages.
Firstly, it enables a high data reduction.
Secondly, this representation concentrates on principal features of the shape, so it is
efficient for shape matching, feature extraction or decomposition of curve into meanningful parts.
Therefore, these points have a critical role in curve approximation, shape matching and image matching.
They also lead to some applications in other domains of machine vision such as vector data compression.

Starting from Attneave's work, there are many existing methods for dominant points detection.
Concerning this problem, several problems in this topic have been identified: evaluation, number of
parameters, selection of starting point, multi-scale, working with noisy curves, \dots.

In general, we can classify these methods into two groups.
The first one contains direct methods that determine dominant points such as high curvature
value points by using curvature-based significant measures, or using alternative significant
measures such as k-cosine, region of support (ROS). Rosenfield and Johnston used cosine of the
angle between the archs of length k on each side of a point (termed k-cosine) as curvature-based
significant measure.
The indirect methods are often based on polygonal approxiamation of the curve,
the dominant points are deduced after doing this step.
In these methods, the dominant points are detected as the vertex of approximated polygons.
In addition, we can divide polygonal approximation methods into three principal approaches:
sequential approach, split and merge approch, heuristic search one.
For sequential approach, Ray and Ray determined the longest possible line segement
with minimum error. Kolesnikov proposed a sub-optimal algorithm for polygon
approximation of closed curves based on the corresponding optimal dynamic programming
algorithm for open curves.
Aoyama used a linear scan to evaluate error condtions, if the conditions are not satisfied,
a new segment search is started. The problem of this method is that sometimes the nodes
do not correspond to the corners because a new vector is defined only when the condtions
are violated.
For split-and-merge methods, lines are fitted to an intial segmentation of the boundary
and then the least square error is computed. These methods then iteratively split
a line if the error is too large and merge two points if the error is too small.
Heuristic approach is used to reduce the complexity of an optimal algorithm for approximating
polygon. Genetic algorithm, tabu search, ant colony search, fuzzy ressning are some
popular techniques approach is simple and fast, but the quality of its result depends on the
starting point.
Masood has proposed an efficient method taht does not belong to any of the above groups.
It is based on break point extraction. A break point is a point of which the chain code
is different from that of the previous point. Break points are taken as initial set of
dominat points. Each break point are taken as initial set of dominant points.

\subsection{Hough Transform}
\label{sub:Hough Transform}

\subsection{Previous Methods}
\label{sub:Previous Methods}

\subsection{Critical Point}
\label{sub:Critical Point}

\subsection{Polygonal Approximation}
\label{sub:polygon}

\subsection{Computational Geometry}
\label{sub:Computational Geometry}

\subsection{My Method}
\label{sub:My Method}

We adopt ideas from data clustering and machine vision

\section{Vertex Extraction for Convex Polygon}
\label{sec:Vertex Extraction for Convex Polygon}
Given a possibily noisy closed curve of a polygon, we want to get the exact
coordinates of its vetices. The proposed method is a global method, we take
all points into consideration at once. Many local methods have been propsed
for detecting critical point in digital curves, but due to the possible noise in the curve,
a completely local method wouldn't be feasible for vertex extraction.

The main procedure of our algorithm is shown

\begin{algorithm}[h]  % h是什么意思？以前查过，现在忘了
  \small              % small不知是什么意思
  \SetKwFunction{FindConvexHull}{FindConvexHull}
  \SetKwFunction{Kmeans}{K-Means-Clustering}
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwInOut{Task}{Task}
  \Task{Extract vertices of a convex polygonal contour}
  \Input{The contour $\mathbf{C}$, number of vertices $n$}
  \Output{Coordinates of $n$ vertices}
  \BlankLine
  $hull \leftarrow$  \FindConvexHull{$\mathbf{C}$} \;
  $l \leftarrow$  number of points in $hull$ \;
  $vectors \leftarrow $  empty list \;
  \For{$i\leftarrow 1$ \KwTo $l$}{
    \tcp*[h]{compute direction vector} \;
    $v \leftarrow \mathbf{C}[(i+1)\mod l] - \mathbf{C}[i] $  \;
    \tcp*[h]{normalize to unit vector} \;
    $v \leftarrow$   $v$ $/$ $\Vert$ $v$ $\Vert$ \;
    $vectors$.add(v) \;
  }
  $indexes \leftarrow$ \Kmeans{$vectors$, $n$} \;
  \emph{seperate points in $hull$ into $n$ sets by $indexes$ } \;
  $lines \leftarrow$ fit the points in each set to a line \;
  $vertices \leftarrow$ the intersection of adjacent lines \;
  \Return $vertices$
  \caption{Vertex Extraction for Convex Polygon}
  \label{algo_convex_polygon}
\end{algorithm}

\begin{algorithm}[h]
  \small
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwInOut{Task}{Task}
  \SetKwFunction{FitModel}{Fit-Model}
  \Task{Extract vertices of a general polygonal contour}
  \Input{The contour $\mathbf{C}$, number of vertices $n$}
  \Output{Coordinates of $n$ vertices}
  \BlankLine
  $inlinerRate \leftarrow -1$ \;
  $lines \leftarrow$ empty list \;
  $N \leftarrow 100 $\;
  $d \leftarrow 2.5 $\;
  \tcp*[h]{main procedure of RANSAC} \;
  \For{$i\leftarrow 1$ \KwTo $N$}{
    \tcp*[h]{one pass for model fitting} \;
    $linesNew, inlinerRateNew \leftarrow$ \FitModel{ $\mathbf{C}$, $n$ }\;
    \If{$inlinerRateNew > inlinerRate$} {
      $inlinerRate \leftarrow inlinerRateNew$ \;
      $lines \leftarrow linesNew$ \;
    }
  }
  $lines \leftarrow$ fit the points in each set to a line \;
  $vertices \leftarrow$ the intersection of adjacent lines \;
  \Return $vertices$
  \caption{Vertex Extraction for General Polygon}\label{algo_nonconvex_polygon}
\end{algorithm}

\begin{algorithm}[h]
  \small
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwInOut{Task}{Task}
  \Task{Fit contour with lines}
  \Input{The contour $\mathbf{C}$, number of lines $n$}

\end{algorithm}

\IncMargin{1em}
\begin{algorithm}
  \small
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
  \Input{A bitmap $Im$ of size $w\times l$}
  \Output{A partition of the bitmap}
  \BlankLine
  \emph{special treatment of the first line}\;
  \For{$i\leftarrow 2$ \KwTo $l$}{
    \emph{special treatment of the first element of line $i$}\;
    \For{$j\leftarrow 2$ \KwTo $w$}{\label{forins}
      \Left$\leftarrow$ \FindCompress{$Im[i,j-1]$}\;
      \Up$\leftarrow$ \FindCompress{$Im[i-1,]$}\;
      \This$\leftarrow$ \FindCompress{$Im[i,j]$}\;
      \If(\tcp*[h]{O(\Left,\This)==1}){\Left compatible with \This}{\label{lt}
        \lIf{\Left $<$ \This}{\Union{\Left,\This}}\;
        \lElse{\Union{\This,\Left}\;}
      }
      \If(\tcp*[f]{O(\Up,\This)==1}){\Up compatible with \This}{\label{ut}
        \lIf{\Up $<$ \This}{\Union{\Up,\This}}\;
        \tcp{\This is put under \Up to keep tree as flat as possible}\label{cmt}
        \lElse{\Union{\This,\Up}}\tcp*[r]{\This linked to \Up}\label{lelse}
} }
    \lForEach{element $e$ of the line $i$}{\FindCompress{p}}
  }
  \caption{disjoint decomposition}\label{algo_disjdecomp}
\end{algorithm}\DecMargin{1em}

\section{ILLUSTRATIONS, GRAPHS, AND PHOTOGRAPHS}
\label{sec:illust}

Illustrations must appear within the designated margins.  They may span the two
columns.  If possible, position illustrations at the top of columns, rather
than in the middle or at the bottom.  Caption and number every illustration.
All halftone illustrations must be clear black and white prints.  Colors may be
used, but they should be selected so as to be readable when printed on a
black-only printer.

Since there are many ways, often incompatible, of including images (e.g., with
experimental results) in a LaTeX document, below is an example of how to do
this \cite{Lamp86}.

\section{FOOTNOTES}
\label{sec:foot}

Use footnotes sparingly (or not at all!) and place them at the bottom of the
column on the page on which they are referenced. Use Times 9-point type,
single-spaced. To help your readers, avoid using footnotes altogether and
include necessary peripheral observations in the text (within parentheses, if
you prefer, as in this sentence).

% Below is an example of how to insert images. Delete the ``\vspace'' line,
% uncomment the preceding line ``\centerline...'' and replace ``imageX.ps''
% with a suitable PostScript file name.
% -------------------------------------------------------------------------
\begin{figure}[t]

\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\includegraphics[width=8.5cm]{Figures/image1}}
%  \vspace{2.0cm}
  \centerline{(a) Result 1}\medskip
\end{minipage}
%
\begin{minipage}[b]{.48\linewidth}
  \centering
  \centerline{\includegraphics[width=4.0cm]{Figures/image3}}
%  \vspace{1.5cm}
  \centerline{(b) Results 3}\medskip
\end{minipage}
\hfill
\begin{minipage}[b]{0.48\linewidth}
  \centering
  \centerline{\includegraphics[width=4.0cm]{Figures/image4}}
%  \vspace{1.5cm}
  \centerline{(c) Result 4}\medskip
\end{minipage}
%
\caption{Example of placing a figure with experimental results.}
\label{fig:res}
%
\end{figure}


% To start a new column (but not a new page) and help balance the last-page
% column length use \vfill\pagebreak.
% -------------------------------------------------------------------------
%\vfill
%\pagebreak

\section{COPYRIGHT FORMS}
\label{sec:copyright}

You must include your fully completed, signed IEEE copyright release form when
form when you submit your paper. We {\bf must} have this form before your paper
can be published in the proceedings.

\section{REFERENCES}
\label{sec:ref}

List and number all bibliographical references at the end of the
paper. The references can be numbered in alphabetic order or in
order of appearance in the document. When referring to them in
the text, type the corresponding reference number in square
brackets as shown at the end of this sentence \cite{C2}. An
additional final page (the fifth page, in most cases) is
allowed, but must contain only references to the prior
literature.

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: refs). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{refs}

\end{document}
